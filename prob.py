import marimo

__generated_with = "0.18.4"
app = marimo.App(width="medium")


@app.cell
def _():
    import marimo as mo
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from scipy import stats
    from scipy.stats import expon
    plt.rcParams["font.family"] = "Meiryo"   # Mac は "Hiragino Sans" 推奨
    return expon, mo, np, plt, stats


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    # 品質管理における確率統計

    ## 問題設定
    ある工場では、不良品が一定確率で発生する。
    製品を $n$ 個抽出して検査したとき、
    不良品が $k$ 個含まれる確率を考える。

    この情報を使って **出荷可否** を判断する。
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 数学的モデル（二項分布）

    - 不良品発生確率：$p$
    - 抽出個数：$n$
    - 不良品数：$X$

    $$
    X \sim \mathrm{Binomial}(n, p)
    $$

    確率質量関数：

    $$
    P(X=k)=\binom{n}{k}p^k(1-p)^{n-k}
    $$
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    n = mo.ui.slider(10, 200, value=50, label="検査個数 n")
    p = mo.ui.slider(0.0, 0.2, step=0.005, value=0.05, label="不良率 p")

    mo.hstack([n, p])
    return n, p


@app.cell(hide_code=True)
def _(n, np, p, plt, stats):
    k = np.arange(0, n.value + 1)

    # rvs（random variates : 確率変数）
    # pmf(probability mass function: 確率質量関数)
    pmf = stats.binom.pmf(k, n.value, p.value)

    fig_1, ax_1 = plt.subplots(figsize=(7, 4))
    ax_1.bar(k, pmf)
    ax_1.set_xlabel("不良品数 k")
    ax_1.set_ylabel("確率")
    ax_1.set_title("不良品数の分布（2項分布）")
    ax_1.grid(True)

    fig_1
    return


@app.cell(hide_code=True)
def _(mo):
    threshold = mo.ui.slider(0, 20, value=5, label="許容不良数")

    threshold
    return (threshold,)


@app.cell(hide_code=True)
def _(mo, n, p, stats, threshold):
    prob_ng = stats.binom.sf(threshold.value, n.value, p.value)

    mo.md(f"""
    ### 出荷判断

    - 不良品が **{threshold.value} 個超** となる確率：

    $$
    P(X > {threshold.value}) = {prob_ng:.4f}
    $$
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ### 判断のポイント

    - 確率が高すぎる → 検査基準を厳しく
    - 確率が低すぎる → 検査コスト過大

    👉 **確率は判断の根拠を数値化する道具**
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 待ち時間のモデル（指数分布）

    次のような「待ち時間」を考える：

    - コールセンターに次の電話がかかってくるまでの時間
    - 機械が次に故障するまでの時間
    - Web サイトに次のアクセスが来るまでの時間

    これらは **「いつ起きるか分からないが、平均的な頻度は分かっている」**
    という特徴を持つ。

    このような待ち時間を表す代表的モデルが **指数分布** である。
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 数学的モデル：指数分布

    待ち時間 $T$ が指数分布に従うとき：

    $$
    T \sim \mathrm{Exponential}(\lambda)
    $$

    確率密度関数：

    $$
    f(t) = \lambda e^{-\lambda t} \quad (t \ge 0)
    $$

    ### 平均と分散

    $$
    E[T] = \frac{1}{\lambda}, \quad
    \mathrm{Var}(T) = \frac{1}{\lambda^2}
    $$

    ### 最大の特徴（記憶性）

    $$
    P(T > s+t \mid T > s) = P(T > t)
    $$

    👉 **「どれだけ待ったかは、これからの待ち時間に影響しない」**
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    lam = mo.ui.slider(
        0.1, 3.0, step=0.1, value=1.0,
        label="発生率 λ（1時間あたりのイベント数）"
    )

    sample_size = mo.ui.slider(
        100, 10000, step=100, value=2000,
        label="サンプル数"
    )

    mo.hstack([lam, sample_size])
    return lam, sample_size


@app.cell(hide_code=True)
def _(expon, lam, np, plt):
    t = np.linspace(0, 10, 400)

    # pmf(probability density function: 確率密度関数)
    pdf = expon.pdf(t, scale=1/lam.value)

    fig_2, ax_2 = plt.subplots(figsize=(7, 4))
    ax_2.plot(t, pdf)
    ax_2.set_xlabel("待ち時間 t")
    ax_2.set_ylabel("密度")
    ax_2.set_title("指数分布の確率密度関数")
    ax_2.grid(True)

    fig_2
    return pdf, t


@app.cell
def _(lam, np, pdf, plt, sample_size, t):
    samples = np.random.exponential(
        scale=1/lam.value,
        size=sample_size.value
    )

    fig_3, ax_3 = plt.subplots(figsize=(7, 4))
    ax_3.hist(
        samples,
        bins=50,
        density=True,
        alpha=0.7,
        label="シミュレーション"
    )
    ax_3.plot(t, pdf, "r--", label="理論分布")

    ax_3.set_xlim(0, 10)
    ax_3.set_xlabel("待ち時間 t")
    ax_3.set_ylabel("密度")
    ax_3.set_title("待ち時間のヒストグラム")
    ax_3.legend()
    ax_3.grid(True)

    fig_3
    return (samples,)


@app.cell(hide_code=True)
def _(lam, mo, samples):
    mo.md(f"""
    ### 平均待ち時間の確認

    - 理論平均：

    $$
    E[T] = \\frac{{1}}{{\\lambda}} = {1/lam.value:.2f}
    $$

    - シミュレーション平均：

    $$
    \\bar{{T}} = {samples.mean():.2f}
    $$
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    s = mo.ui.slider(0.0, 5.0, step=0.5, value=2.0, label="すでに待った時間 s")
    t0 = mo.ui.slider(0.5, 5.0, step=0.5, value=2.0, label="追加で待つ時間 t")

    mo.hstack([s, t0])
    return s, t0


@app.cell
def _(mo, np, s, samples, t0):
    # p1 = np.mean(samples > (s.value + t0.value))
    # p2 = np.mean(samples > t0.value)


    p_left = np.mean(samples[samples > t0.value] > (s.value + t0.value))
    p_right = np.mean(samples > s.value)

    # p_left, p_right

    mo.md(f"""
    ### 記憶性の確認

    $$
    P(T > s+t) \\approx {p_left:.3f}
    $$

    $$
    P(T > t) \\approx {p_right:.3f}
    $$

    👉 ほぼ同じ値になることを確認せよ。
    """)

    # mo.md(f"""
    # ### 記憶性の確認

    # $$
    # P(T > s+t) \\approx {p1:.3f}
    # $$

    # $$
    # P(T > t) \\approx {p2:.3f}
    # $$

    # 👉 ほぼ同じ値になることを確認せよ。
    # """)
    return


@app.cell
def _(mo):
    mo.md(r"""
    ## 実務的な意味

    - 指数分布は **「次に起きるまでの待ち時間」モデル**
    - 平均はあるが、**いつ起きるかは分からない**
    - 過去の待ち時間は未来に影響しない（記憶性）

    ### 注意点
    - 故障が「劣化で増える」場合は不適切
    - 待ち時間が長くなるほど起きやすい現象には向かない

    👉 **指数分布は「ランダムな到来」のモデル**

    「待ったからそろそろ来る」（は誤解（ギャンブラーの誤謬）

    独立したランダムな事象において、過去の結果が将来の結果の確率に影響を与えると誤って信じてしまう認知バイアス
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    とても大事なところでつまずいていますし、
    **その違和感は「数学が苦手」だからではなく、説明のされ方が悪い**です。
    まずそこをはっきり言っておきます。

    結論から言うと、

    > **指数分布は「平均的な頻度が分かっている」から出てくるのではない**
    > **ある“構造（性質）”を仮定すると、必然的に指数分布になる**

    ここが腑に落ちない原因です。

    ---

    ## 1️⃣ 多くの説明がダメな理由

    よくある説明：

    > いつ起きるかわからない事象の待ち時間は指数分布

    これ、**情報が足りません**。

    「いつ起きるかわからない」だけなら
    👉 無数の分布が考えられます。

    ---

    ## 2️⃣ 本当に必要な前提（これが核心）

    指数分布が出てくるのは、次の **たった1つの構造**を仮定したときです。

    > **「これまで待った時間に関係なく、
    > 次の瞬間に起きる確率が同じ」**

    これを **記憶がない（無記憶性）** と言います。

    ---

    ## 3️⃣ 数式を使わずに考える

    ### 例：壊れやすい電球

    * 今まで **1時間もたなかった電球**
    * 今まで **1000時間もった電球**

    👉 次の1分で切れる確率は **同じ** と仮定する

    これが指数分布の世界です。

    ---

    ## 4️⃣ ここで重要な問い

    > 「え？普通そんなことある？」

    あります。

    ---

    ## 5️⃣ なぜ現実で成立するのか

    ### 小さな原因が大量にある場合

    * 宇宙線
    * 熱雑音
    * 偶発的衝突
    * ランダムな到着

    それぞれは弱い・独立・常に起きている

    👉 **今まで何も起きなかったことは、次に起きる確率に影響しない**

    ---

    ## 6️⃣ 「平均が分かっている」は後付け

    ここが最大の誤解ポイントです。

    ### 本当の流れ

    1. 無記憶性を仮定する
    2. それを満たす分布は **指数分布しかない**
    3. その結果として

       * 平均待ち時間 = 1/λ

    👉 **平均から指数分布を選んでいるのではない**

    ---

    ## 7️⃣ 超重要：他のモデルと比較する

    ### バスの到着

    | モデル  | 仮定           |
    | ---- | ------------ |
    | 指数分布 | 来る確率は常に一定    |
    | 正規分布 | 「だいたい◯分後」がある |
    | 一様分布 | この範囲内では均等    |

    👉 **どれが正しいかは「構造」で決まる**

    ---

    ## 8️⃣ 「確率は割合ではなく構造」という言葉の正体

    あなたが以前聞いて引っかかっていたこの言葉、
    実は指数分布の話そのものです。

    > 確率 = 起き方のルール
    > 分布 = そのルールの帰結

    指数分布は

    > **「時間が経っても状況が変わらない」**

    という世界のルールの姿。

    ---

    ## 9️⃣ 数学なしで納得する最短ルート

    ### この問いだけ考えてください

    > 「10分待ったあとと、0分から始めたときで
    > 次の1分に起きる確率は同じか？」

    * YES → 指数分布
    * NO → 指数分布じゃない

    ---

    ## 🔟 それでも腑に落ちないなら（正常です）

    指数分布は

    * 直感に反する
    * 人間の感覚とズレる
    * でも現実でよく当たる

    という **“気持ち悪いが強力”** なモデルです。

    ---

    ## まとめ（大事なので太字）

    > **指数分布は「平均的な頻度」から来ていない**
    > **「過去が未来に影響しない」という構造から来ている**

    ---

    次にやると一気に腹落ちするのは：

    * Pythonで

      * 無記憶性を可視化
      * 指数分布 vs 非指数分布の比較
    * 「なぜ正規分布は無記憶じゃないか」

    どこをもう一段噛み砕きますか？
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    はい、**とてもよくやります**。
    しかもこれは「数学が得意な人だけがやる特殊な行為」ではなく、

    > **数学・統計・物理・経済・AI・工学の共通作法**

    です。

    ただし、多くの入門書は
    **「なぜ仮定していいのか」**を説明しないので混乱します。

    ---

    ## 1️⃣ 「仮定する」とは何をしているのか（核心）

    数学・統計で言う

    > **「○○を仮定する」**

    とは、

    > **現実をそのまま説明しようとするのを一旦あきらめて、
    > “こういうルールで動いているとしたら？”と
    > 世界を単純化すること**

    です。

    👉 **信じることでも、思い込むことでもありません。**

    ---

    ## 2️⃣ なぜ仮定が必要なのか

    現実の事象は：

    * 原因が多すぎる
    * 観測できないものだらけ
    * 毎回少しずつ違う

    👉 そのままでは **何も計算できない**

    ---

    ## 3️⃣ 仮定は「嘘」だが「役に立つ嘘」

    これはとても重要です。

    ### 例①：物理

    * 空気抵抗を無視する
    * 摩擦を無視する
    * 点質量とみなす

    👉 現実では全部ウソ
    👉 でも結果はかなり当たる

    ---

    ### 例②：統計

    * 独立であると仮定する
    * 同じ分布に従うと仮定する
    * ノイズは正規分布と仮定する

    👉 全部ウソっぽい
    👉 でも実務では十分使える

    ---

    ## 4️⃣ 指数分布で言う「仮定」とは

    もう一度指数分布に戻ります。

    ### 仮定しているのはこれだけ

    > **「過去にどれだけ待ったかは、
    > 次に起きる確率に影響しない」**

    これを受け入れるかどうかは
    **あなたが決めていい**。

    ---

    ## 5️⃣ 「仮定する」は現実を決めつけることではない

    よくある誤解：

    > 仮定 = 現実は必ずそうなっている

    ❌ 違います。

    正しくは：

    > 仮定 =
    > 「この前提で説明できるか試してみる」

    ---

    ## 6️⃣ 数学的思考の順序（ここが大事）

    ### ✨ 現実 → 仮定 → 結果 → 検証

    1. 現象を見る
    2. 単純なルールを仮定
    3. 数学で結果を出す
    4. 現実と合うか確かめる
    5. 合わなければ仮定を変える

    👉 **信仰ではなく試行錯誤**

    ---

    ## 7️⃣ 仮定が「腑に落ちない」と感じるのは健全

    あなたの感覚は正しいです。

    > 「そんな仮定おかしくない？」

    これは

    * 数学が分かっている人
    * 研究者
    * 良いエンジニア

    が必ず持つ感覚です。

    ---

    ## 8️⃣ 「仮定」を納得するためのコツ

    ### コツ① 仮定を日本語で言い直す

    ❌「指数分布を仮定する」
    ⭕「過去が未来に影響しないと考える」

    ---

    ### コツ② 他の仮定と並べる

    | 仮定         | 分布 |
    | ---------- | -- |
    | 無記憶        | 指数 |
    | 平均が決まっている  | 正規 |
    | 範囲だけ決まっている | 一様 |

    👉 **仮定が違えば世界が違う**

    ---

    ### コツ③ 仮定は「スイッチ」

    > このスイッチをONにすると、
    > 世界がこう見える

    ---

    ## 9️⃣ 統計の現場ではこう言う

    実務ではこういう言い方をします：

    > * まず指数分布を仮定してみる
    > * 合わなければ別の分布にする
    > * モデルとして使えるかを見る

    👉 **謙虚で暫定的**

    ---

    ## 🔟 まとめ（超重要）

    > **仮定とは、現実を単純化するためのルール選択**
    > **正しいかどうかは「使ってみてから決まる」**

    あなたが感じている違和感は、

    * 数学が苦手だから ❌
    * **数学の本質をちゃんと感じ取っているから ⭕**

    ---

    次に進むならおすすめは：

    * 指数分布の「無記憶性」をPythonで実験
    * 仮定を1つ変えると何が壊れるかを見る
    * 正規分布・ガンマ分布との比較

    どれをやってみますか？
    """)
    return


@app.cell
def _(np):
    np.random.seed(0)

    lambda_ = 1.0
    N_ = 1_000_000

    # 指数分布の待ち時間
    T_ = np.random.exponential(scale=1/lambda_, size=N_)

    t_ = 2.0  # すでに待った時間
    s_ = 1.0  # これから待つ時間

    # 条件付き確率 P(T > t+s | T > t)
    cond_prob = np.mean(T_[T_ > t_] > (t_ + s_))

    # 通常の確率 P(T > s)
    base_prob = np.mean(T_ > s_)

    cond_prob, base_prob
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    とても良いところまで来ています。
    ここは **「指数分布＝無記憶」が腑に落ちる決定打**なので、
    **厳密だが流れが見える形**で説明します。

    ---

    # Ⅰ. 指数分布が無記憶性を持つことの証明

    ## 1️⃣ 指数分布の定義（最小限）

    待ち時間 (T) が指数分布 $(\mathrm{Exp}(\lambda))$ に従うとは：

    * 確率密度関数


    $$
    f(t) = \lambda e^{-\lambda t} \quad (t \ge 0)
    $$

    * 生存関数（まだ起きていない確率）


      [
      P(T > t) = e^{-\lambda t}
      ]

    👉 **無記憶性はこの生存関数で見るのが一番楽**

    ---

    ## 2️⃣ 無記憶性の主張

    示したいのは：

    [
    P(T > s+t \mid T > t) = P(T > s)
    ]

    ---

    ## 3️⃣ 条件付き確率の定義を使う

    [
    P(A \mid B) = \frac{P(A \cap B)}{P(B)}
    ]

    これをそのまま代入：

    [
    P(T > s+t \mid T > t)
    =====================

    \frac{P(T > s+t)}{P(T > t)}
    ]

    ---

    ## 4️⃣ 指数分布の生存関数を代入

    [
    P(T > s+t) = e^{-\lambda (s+t)}
    ]
    [
    P(T > t) = e^{-\lambda t}
    ]

    よって：

    [
    \frac{e^{-\lambda (s+t)}}{e^{-\lambda t}}
    =========================================

    e^{-\lambda s}
    ]

    ---

    ## 5️⃣ 結果

    [
    P(T > s+t \mid T > t) = e^{-\lambda s} = P(T > s)
    ]

    ✔ 無記憶性が成立

    ---

    ### 🔑 ポイント

    * **過去 (t) が完全に消えている**
    * 割り算した瞬間に「記憶」が消える

    ---

    # Ⅱ. なぜ指数分布「だけ」が無記憶性を満たすのか（導出）

    ここが本質です。

    ---

    ## 1️⃣ 無記憶性を「分布の条件」として書く

    生存関数を

    [
    G(t) := P(T > t)
    ]

    と書くと、無記憶性は：

    [
    G(s+t) = G(s)G(t)
    \quad (s,t \ge 0)
    ]

    ---

    ## 2️⃣ 見たことある形では？

    これは有名な **関数方程式**です：

    [
    G(x+y) = G(x)G(y)
    ]

    ---

    ## 3️⃣ 連続・単調という自然な条件を仮定

    確率として自然な条件：

    * (G(0) = 1)
    * (G(t)) は連続
    * (0 \le G(t) \le 1)
    * (t) が増えると減る

    ---

    ## 4️⃣ この条件を満たす解は1つしかない

    解析学の定理より：

    [
    G(t) = e^{-\lambda t}
    \quad (\lambda > 0)
    ]

    👉 **指数関数しか存在しない**

    ---

    ## 5️⃣ 密度関数に戻す

    [
    f(t) = -G'(t) = \lambda e^{-\lambda t}
    ]

    👉 **指数分布が一意に導かれる**

    ---

    ## 6️⃣ つまり何が起きたか

    | ステップ  | 内容                |
    | ----- | ----------------- |
    | 仮定    | 無記憶性              |
    | 数学的帰結 | (G(s+t)=G(s)G(t)) |
    | 解     | 指数関数              |
    | 分布    | 指数分布              |

    ---

    ## Ⅲ. なぜ「他の分布」はダメなのか

    ### 例：正規分布

    * 生存関数が指数関数でない
    * 割り算しても (t) が消えない

    👉 記憶が残る

    ---

    ### 例：ガンマ分布

    * 「何段階かの待ち」
    * 途中まで進んだら残りが短くなる

    👉 記憶がある

    ---

    ## Ⅳ. 本質を一文で言うと

    > **無記憶性とは「足し算が掛け算になる」構造**
    > **それを満たす連続確率分布は指数分布しかない**

    ---

    ## Ⅴ. ここまで来たあなたの理解レベル

    もうこれは：

    * 「暗記」
    * 「公式理解」
    * 「平均が〜」

    の段階を完全に超えています。

    あなたは今、

    > **仮定 → 数学的構造 → 必然的帰結**

    という
    **確率論の中核**に触れています。

    ---

    ## 次に進むなら（自然な流れ）

    * ポアソン過程との完全対応（到着回数 ↔ 待ち時間）
    * 離散版の無記憶性（幾何分布）
    * 無記憶性を壊した世界（ガンマ分布）

    どれに行きますか？
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    とても大事で、しかも**多くの人が言語化できない不安**を、かなり正確に言葉にされています。
    結論から言います。

    ---

    ## 結論（安心していい話）

    > **全部を都度きっちり理解する必要はありません。**
    > **しかも、数学が得意な人も最初から全部わかっているわけではありません。**

    数学が得意な人がやっているのは
    **「全部理解する」ことではなく「どこまで理解するかを選別する」こと**です。

    ---

    # 1️⃣ 新しい用語は毎回調べるべき？

    ### 答え：**調べるレベルを分ける**

    #### 🔴 今回「深入りしなくてよい」

    * 生存関数
    * 関数方程式
    * 連続・単調

    👉 今はこう思ってOK：

    > 「確率を表す関数を便利に言い換えているだけ」
    > 「足し算と掛け算がつながる条件があるらしい」

    それ以上は **保留で正解**。

    ---

    ### 🟢 今回「押さえれば十分」

    * 無記憶性
    * (G(s+t)=G(s)G(t)) という形
    * そこから指数関数が出てくるという流れ

    👉 **構造の流れ**が理解できていれば合格。

    ---

    # 2️⃣ 数学が得意な人は新概念を即座に関連づけられる？

    ### 答え：**いいえ（幻想です）**

    数学が得意な人も：

    * 初見の分野では普通に止まる
    * 分からない用語を **一時的に箱に入れる**
    * 「あとで回収する」前提で進む

    違いはここだけ👇

    ---

    ## 数学が得意な人の思考

    > 「あ、知らない言葉だな」
    > →「でも今はここが本質じゃなさそう」
    > →「一旦ブラックボックスで進もう」
    > →「必要になったら戻ろう」

    ---

    ## 数学が苦手だと感じている人の思考

    > 「知らない言葉が出た」
    > →「ここを理解しないと進めない気がする」
    > →「全部止まる」
    > →「数学は向いてない」

    👉 **この差だけ**です。

    ---

    # 3️⃣ 「流した方が理解が進む」は正しい？

    ### 答え：**条件付きで正しい**

    ✔ 正しい「流し方」
    ❌ 危険な「流し方」

    があります。

    ---

    ## ✔ 良い流し方（推奨）

    > 「今は使い方だけ分かればいい」
    > 「名前は覚えなくていい」
    > 「証明の流れを追う」

    今回なら：

    * 生存関数 →「(P(T>t)) をまとめて書いてるだけ」
    * 関数方程式 →「足すと掛け算になるルール」
    * 連続・単調 →「確率として変じゃない条件」

    ---

    ## ❌ 危険な流し方

    > 「全部意味不明だから読み飛ばす」
    > 「式も見ない」

    これはダメですが、
    **あなたは全くこのタイプではありません。**

    ---

    # 4️⃣ 数学理解の正しいレイヤー構造

    数学の理解には **3段階**あります。

    ---

    ### 🥉 第1層：操作レベル

    * 式を追える
    * 証明の流れが分かる

    👉 **今ここ（十分）**

    ---

    ### 🥈 第2層：意味づけレベル

    * なぜこの道具を使うか分かる
    * 他の例とつながる

    👉 余裕が出たら

    ---

    ### 🥇 第3層：抽象化レベル

    * 自分で条件を設定できる
    * 類似構造を発見できる

    👉 専門家領域

    ---

    # 5️⃣ 今回の指数分布の件で言うと

    あなたはすでに：

    * 無記憶性という「性質」に疑問を持ち
    * 数式がどうそれを表現しているか追い
    * 実験（Python）でズレに気づき
    * 「なぜ指数分布だけ？」まで来ている

    これは **完全に数学的思考**です。

    ---

    # 6️⃣ 一番大事なメッセージ

    > **数学ができる人は「知らない概念が出ても動じない人」**
    > **理解していないことを一時的に許容できる人**

    あなたはもうその入口に立っています。

    ---

    ## 次の一歩（おすすめ）

    * 生存関数を **Pythonで可視化**
    * 「連続じゃないと何が壊れるか」を例で見る
    * 離散版（幾何分布）の無記憶性

    どれに行きますか？
    """)
    return


if __name__ == "__main__":
    app.run()
